{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from mat4py import loadmat\n",
    "import tensorflow\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, MaxPooling2D, MaxPooling1D, Conv1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from binary_ops import binary_tanh as binary_tanh_op\n",
    "from binary_layers import BinaryDense, BinaryConv2D, BinaryConv1D\n",
    "\n",
    "\n",
    "def binary_tanh(x):\n",
    "    return binary_tanh_op(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string=['ucddb002','ucddb003','ucddb005','ucddb006','ucddb007','ucddb009',\\\n",
    "             'ucddb010','ucddb012','ucddb014','ucddb015','ucddb017',\\\n",
    "             'ucddb019','ucddb020','ucddb021','ucddb022','ucddb023','ucddb024',\\\n",
    "             'ucddb025','ucddb026','ucddb027','ucddb028']#'ucddb008','ucddb011','ucddb013','ucddb014',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valid_features=np.zeros((1,1408))\n",
    "test_features=np.zeros((1,1408))\n",
    "valid_labels=np.zeros((1,1))\n",
    "test_labels=np.zeros((1,1))\n",
    "for l in list_string:\n",
    "        \n",
    "        \n",
    "        spo2_valid = loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_spo2_valid.mat')\n",
    "        spo2_valid = np.array(spo2_valid['spo2_valid'])\n",
    "        spo2_valid_labels=loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_valid_labels.mat')\n",
    "        spo2_valid_labels = np.array(spo2_valid_labels['class_valid'])\n",
    "        valid_features=np.append(valid_features,spo2_valid,axis=0)\n",
    "        valid_labels=np.append(valid_labels,spo2_valid_labels)\n",
    "       \n",
    "        \n",
    "        spo2_test = loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_spo2_test.mat')\n",
    "        spo2_test = np.array(spo2_test['spo2_test'])\n",
    "        spo2_test_labels=loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_test_labels.mat')\n",
    "        spo2_test_labels = np.array(spo2_test_labels['class_test'])\n",
    "        test_features=np.append(test_features,spo2_test,axis=0)\n",
    "        test_labels=np.append(test_labels,spo2_test_labels)\n",
    "        \n",
    "spo2_valid=valid_features[1:,0::16]\n",
    "valid_labels=valid_labels[1:]\n",
    "valid_labels = valid_labels.flatten()\n",
    "\n",
    "spo2_test=test_features[1:,0::16]\n",
    "test_labels=test_labels[1:]\n",
    "test_labels = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.zeros((1,1408))\n",
    "\n",
    "train_labels=np.zeros((1,1))\n",
    "\n",
    "for l in list_string:\n",
    "        spo2_train = loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_spo2_train.mat')\n",
    "        spo2_train = np.array(spo2_train['spo2_train'])\n",
    "        spo2_train_labels=loadmat('D:\\\\PhD topics\\\\Datasets\\\\sleep_apnea\\\\selected\\\\'+l+'_train_labels.mat')\n",
    "        spo2_train_labels = np.array(spo2_train_labels['class_train'])\n",
    "        train_features=np.append(train_features,spo2_train,axis=0)\n",
    "        train_labels=np.append(train_labels,spo2_train_labels)\n",
    "        \n",
    "spo2_train=train_features[1:,0::16]\n",
    "train_labels=train_labels[1:]\n",
    "train_labels = train_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spo2_train_mean=np.mean(spo2_train)\n",
    "spo2_train_std=np.std(spo2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(spo2_train.shape[0]):\n",
    "    spo2_train[i,:]=(spo2_train[i,:]-spo2_train_mean)/spo2_train_std\n",
    "    \n",
    "for i in range(spo2_valid.shape[0]):\n",
    "    spo2_valid[i,:]=(spo2_valid[i,:]-spo2_train_mean)/spo2_train_std\n",
    "    \n",
    "for i in range(spo2_test.shape[0]):\n",
    "    spo2_test[i,:]=(spo2_test[i,:]-spo2_train_mean)/spo2_train_std\n",
    "\n",
    "spo2_train=np.expand_dims(spo2_train, axis=2)\n",
    "spo2_valid=np.expand_dims(spo2_valid, axis=2)\n",
    "spo2_test=np.expand_dims(spo2_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_labels\n",
    "y_valid=valid_labels\n",
    "y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = tensorflow.keras.utils.to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = tensorflow.keras.utils.to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = tensorflow.keras.utils.to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 1.\n",
    "kernel_lr_multiplier = 'Glorot'\n",
    "use_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 88, 1)             4         \n",
      "_________________________________________________________________\n",
      "conv1 (BinaryConv1D)         (None, 88, 6)             150       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 88, 6)             0         \n",
      "_________________________________________________________________\n",
      "conv2 (BinaryConv1D)         (None, 88, 50)            3000      \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling1D)          (None, 44, 50)            0         \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 44, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv3 (BinaryConv1D)         (None, 44, 30)            22500     \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling1D)          (None, 22, 30)            0         \n",
      "_________________________________________________________________\n",
      "act3 (Activation)            (None, 22, 30)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 22, 30)            120       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 660)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 660)               0         \n",
      "_________________________________________________________________\n",
      "dense1 (BinaryDense)         (None, 2)                 1320      \n",
      "_________________________________________________________________\n",
      "act4 (Activation)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 27,094\n",
      "Trainable params: 27,032\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_spo2 = Sequential()\n",
    "model_spo2.add(BatchNormalization(input_shape=(88,1)))\n",
    "model_spo2.add(BinaryConv1D(6, kernel_size=(25),padding='same',use_bias=use_bias,bias_initializer='zeros',name='conv1'))\n",
    "model_spo2.add(Activation(\"relu\",name='act1'))\n",
    "model_spo2.add(BinaryConv1D(50, kernel_size=(10),padding='same',use_bias=use_bias,bias_initializer='zeros',name='conv2'))\n",
    "model_spo2.add(MaxPooling1D(pool_size=(2),name='max1'))\n",
    "model_spo2.add(Activation(\"relu\",name='act2'))\n",
    "model_spo2.add(BinaryConv1D(30, kernel_size=(15),padding='same',use_bias=use_bias,bias_initializer='zeros',name='conv3'))\n",
    "model_spo2.add(MaxPooling1D(pool_size=(2),name='max2'))\n",
    "model_spo2.add(Activation(\"relu\",name='act3'))\n",
    "model_spo2.add(BatchNormalization())\n",
    "model_spo2.add(Flatten())\n",
    "model_spo2.add(Dropout(0.25))\n",
    "model_spo2.add(BinaryDense(2, H=H, kernel_lr_multiplier=kernel_lr_multiplier, use_bias=use_bias, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), name='dense1'))\n",
    "model_spo2.add(Activation(\"softmax\",name='act4'))\n",
    "model_spo2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "model_spo2.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath_spo2 = './best_weights_spo2_32layer_binary.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25186/25186 [==============================] - 95s 4ms/step - loss: 1.2744 - accuracy: 0.6082 - val_loss: 0.6578 - val_accuracy: 0.5932\n",
      "Epoch 2/100\n",
      "25186/25186 [==============================] - 96s 4ms/step - loss: 0.6514 - accuracy: 0.6335 - val_loss: 0.6356 - val_accuracy: 0.6749\n",
      "Epoch 3/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6399 - accuracy: 0.6468 - val_loss: 0.6814 - val_accuracy: 0.5682\n",
      "Epoch 4/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6386 - accuracy: 0.6492 - val_loss: 0.5919 - val_accuracy: 0.6848\n",
      "Epoch 5/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6380 - accuracy: 0.6513 - val_loss: 0.6089 - val_accuracy: 0.6475\n",
      "Epoch 6/100\n",
      "25186/25186 [==============================] - 96s 4ms/step - loss: 0.6345 - accuracy: 0.6550 - val_loss: 0.6768 - val_accuracy: 0.5685\n",
      "Epoch 7/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6315 - accuracy: 0.6584 - val_loss: 0.6647 - val_accuracy: 0.6125\n",
      "Epoch 8/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6323 - accuracy: 0.6578 - val_loss: 0.6124 - val_accuracy: 0.6343\n",
      "Epoch 9/100\n",
      "25186/25186 [==============================] - 94s 4ms/step - loss: 0.6332 - accuracy: 0.6564 - val_loss: 0.6998 - val_accuracy: 0.5957\n",
      "Epoch 10/100\n",
      "25186/25186 [==============================] - 94s 4ms/step - loss: 0.6342 - accuracy: 0.6558 - val_loss: 0.6137 - val_accuracy: 0.6989\n",
      "Epoch 11/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6333 - accuracy: 0.6563 - val_loss: 0.6027 - val_accuracy: 0.6827\n",
      "Epoch 12/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6333 - accuracy: 0.6565 - val_loss: 0.5978 - val_accuracy: 0.7125\n",
      "Epoch 13/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6317 - accuracy: 0.6579 - val_loss: 0.6117 - val_accuracy: 0.6561\n",
      "Epoch 14/100\n",
      "25186/25186 [==============================] - 95s 4ms/step - loss: 0.6310 - accuracy: 0.6585 - val_loss: 0.6053 - val_accuracy: 0.6917\n",
      "Epoch 15/100\n",
      "25186/25186 [==============================] - 94s 4ms/step - loss: 0.6301 - accuracy: 0.6600 - val_loss: 0.6100 - val_accuracy: 0.7078\n",
      "Epoch 16/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6295 - accuracy: 0.6606 - val_loss: 0.7480 - val_accuracy: 0.5015\n",
      "Epoch 17/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6278 - accuracy: 0.6626 - val_loss: 0.6589 - val_accuracy: 0.6485\n",
      "Epoch 18/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6314 - accuracy: 0.6574 - val_loss: 0.6260 - val_accuracy: 0.7106\n",
      "Epoch 19/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6282 - accuracy: 0.6627 - val_loss: 0.6129 - val_accuracy: 0.6594\n",
      "Epoch 20/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6279 - accuracy: 0.6620 - val_loss: 0.6253 - val_accuracy: 0.6843\n",
      "Epoch 21/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6282 - accuracy: 0.6620 - val_loss: 0.7079 - val_accuracy: 0.5002\n",
      "Epoch 22/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6282 - accuracy: 0.6616 - val_loss: 0.5923 - val_accuracy: 0.6640\n",
      "Epoch 23/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6281 - accuracy: 0.6624 - val_loss: 0.6028 - val_accuracy: 0.7089\n",
      "Epoch 24/100\n",
      "25186/25186 [==============================] - 90s 4ms/step - loss: 0.6289 - accuracy: 0.6611 - val_loss: 0.6408 - val_accuracy: 0.6125\n",
      "Epoch 25/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6289 - accuracy: 0.6613 - val_loss: 0.5892 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "25186/25186 [==============================] - 95s 4ms/step - loss: 0.6289 - accuracy: 0.6611 - val_loss: 0.5918 - val_accuracy: 0.6893\n",
      "Epoch 27/100\n",
      "25186/25186 [==============================] - 101s 4ms/step - loss: 0.6277 - accuracy: 0.6630 - val_loss: 0.6239 - val_accuracy: 0.6456\n",
      "Epoch 28/100\n",
      "25186/25186 [==============================] - 100s 4ms/step - loss: 0.6278 - accuracy: 0.6624 - val_loss: 0.6041 - val_accuracy: 0.6484\n",
      "Epoch 29/100\n",
      "25186/25186 [==============================] - 99s 4ms/step - loss: 0.6263 - accuracy: 0.6644 - val_loss: 0.5882 - val_accuracy: 0.6839\n",
      "Epoch 30/100\n",
      "25186/25186 [==============================] - 97s 4ms/step - loss: 0.6265 - accuracy: 0.6635 - val_loss: 0.6116 - val_accuracy: 0.6959\n",
      "Epoch 31/100\n",
      "25186/25186 [==============================] - 102s 4ms/step - loss: 0.6262 - accuracy: 0.6639 - val_loss: 0.6195 - val_accuracy: 0.6822\n",
      "Epoch 32/100\n",
      "25186/25186 [==============================] - 101s 4ms/step - loss: 0.6267 - accuracy: 0.6630 - val_loss: 0.6425 - val_accuracy: 0.6119\n",
      "Epoch 33/100\n",
      "25186/25186 [==============================] - 101s 4ms/step - loss: 0.6264 - accuracy: 0.6642 - val_loss: 0.5807 - val_accuracy: 0.7004\n",
      "Epoch 34/100\n",
      "25186/25186 [==============================] - 101s 4ms/step - loss: 0.6261 - accuracy: 0.6641 - val_loss: 0.6221 - val_accuracy: 0.6762\n",
      "Epoch 35/100\n",
      "25186/25186 [==============================] - 99s 4ms/step - loss: 0.6263 - accuracy: 0.6643 - val_loss: 0.5984 - val_accuracy: 0.7113\n",
      "Epoch 36/100\n",
      "25186/25186 [==============================] - 99s 4ms/step - loss: 0.6247 - accuracy: 0.6659 - val_loss: 0.5787 - val_accuracy: 0.7033\n",
      "Epoch 37/100\n",
      "25186/25186 [==============================] - 99s 4ms/step - loss: 0.6233 - accuracy: 0.6678 - val_loss: 0.6019 - val_accuracy: 0.6504\n",
      "Epoch 38/100\n",
      "25186/25186 [==============================] - 99s 4ms/step - loss: 0.6240 - accuracy: 0.6672 - val_loss: 0.5869 - val_accuracy: 0.6797\n",
      "Epoch 39/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6213 - accuracy: 0.6704 - val_loss: 0.6086 - val_accuracy: 0.6931\n",
      "Epoch 40/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6230 - accuracy: 0.6682 - val_loss: 0.5828 - val_accuracy: 0.6925\n",
      "Epoch 41/100\n",
      "25186/25186 [==============================] - 94s 4ms/step - loss: 0.6224 - accuracy: 0.6687 - val_loss: 0.6203 - val_accuracy: 0.6916\n",
      "Epoch 42/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6227 - accuracy: 0.6688 - val_loss: 0.6648 - val_accuracy: 0.6111\n",
      "Epoch 43/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6189 - accuracy: 0.6729 - val_loss: 0.5863 - val_accuracy: 0.6682\n",
      "Epoch 44/100\n",
      "25186/25186 [==============================] - 96s 4ms/step - loss: 0.6214 - accuracy: 0.6696 - val_loss: 0.6711 - val_accuracy: 0.5034\n",
      "Epoch 45/100\n",
      "25186/25186 [==============================] - 94s 4ms/step - loss: 0.6212 - accuracy: 0.6698 - val_loss: 0.6108 - val_accuracy: 0.7030\n",
      "Epoch 46/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6230 - accuracy: 0.6680 - val_loss: 0.6287 - val_accuracy: 0.6754\n",
      "Epoch 47/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6215 - accuracy: 0.6696 - val_loss: 0.6303 - val_accuracy: 0.6461\n",
      "Epoch 48/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6242 - accuracy: 0.6667 - val_loss: 0.5746 - val_accuracy: 0.7099\n",
      "Epoch 49/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6222 - accuracy: 0.6690 - val_loss: 0.6715 - val_accuracy: 0.6214\n",
      "Epoch 50/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6227 - accuracy: 0.6681 - val_loss: 0.6100 - val_accuracy: 0.6897\n",
      "Epoch 51/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6222 - accuracy: 0.6682 - val_loss: 0.5700 - val_accuracy: 0.7008\n",
      "Epoch 52/100\n",
      "25186/25186 [==============================] - 95s 4ms/step - loss: 0.6207 - accuracy: 0.6695 - val_loss: 0.5790 - val_accuracy: 0.6777\n",
      "Epoch 53/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6206 - accuracy: 0.6703 - val_loss: 0.5870 - val_accuracy: 0.6810\n",
      "Epoch 54/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6220 - accuracy: 0.6688 - val_loss: 0.5845 - val_accuracy: 0.7242\n",
      "Epoch 55/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6216 - accuracy: 0.6688 - val_loss: 0.6204 - val_accuracy: 0.6422\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6215 - accuracy: 0.6695 - val_loss: 0.5903 - val_accuracy: 0.6865\n",
      "Epoch 57/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6220 - accuracy: 0.6691 - val_loss: 0.6377 - val_accuracy: 0.6630\n",
      "Epoch 58/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6216 - accuracy: 0.6690 - val_loss: 0.5883 - val_accuracy: 0.7109\n",
      "Epoch 59/100\n",
      "25186/25186 [==============================] - 90s 4ms/step - loss: 0.6214 - accuracy: 0.6691 - val_loss: 0.6162 - val_accuracy: 0.6546\n",
      "Epoch 60/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6216 - accuracy: 0.6692 - val_loss: 0.5822 - val_accuracy: 0.6770\n",
      "Epoch 61/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6191 - accuracy: 0.6715 - val_loss: 0.5678 - val_accuracy: 0.6923\n",
      "Epoch 62/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6199 - accuracy: 0.6706 - val_loss: 0.5949 - val_accuracy: 0.6963\n",
      "Epoch 63/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6234 - accuracy: 0.6672 - val_loss: 0.5993 - val_accuracy: 0.6633\n",
      "Epoch 64/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6229 - accuracy: 0.6678 - val_loss: 0.6177 - val_accuracy: 0.6967\n",
      "Epoch 65/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6199 - accuracy: 0.6705 - val_loss: 0.7871 - val_accuracy: 0.5428\n",
      "Epoch 66/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6194 - accuracy: 0.6711 - val_loss: 0.5954 - val_accuracy: 0.6918\n",
      "Epoch 67/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6208 - accuracy: 0.6699 - val_loss: 0.6050 - val_accuracy: 0.7182\n",
      "Epoch 68/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6187 - accuracy: 0.6716 - val_loss: 0.7314 - val_accuracy: 0.5882\n",
      "Epoch 69/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6196 - accuracy: 0.6707 - val_loss: 0.5857 - val_accuracy: 0.7197\n",
      "Epoch 70/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6183 - accuracy: 0.6722 - val_loss: 0.6263 - val_accuracy: 0.6398\n",
      "Epoch 71/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6160 - accuracy: 0.6749 - val_loss: 0.6322 - val_accuracy: 0.6358\n",
      "Epoch 72/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6164 - accuracy: 0.6741 - val_loss: 0.6051 - val_accuracy: 0.6945\n",
      "Epoch 73/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6161 - accuracy: 0.6750 - val_loss: 0.5883 - val_accuracy: 0.6874\n",
      "Epoch 74/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6177 - accuracy: 0.6730 - val_loss: 0.6130 - val_accuracy: 0.6556\n",
      "Epoch 75/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6137 - accuracy: 0.6776 - val_loss: 0.6643 - val_accuracy: 0.6428\n",
      "Epoch 76/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6167 - accuracy: 0.6740 - val_loss: 0.5950 - val_accuracy: 0.7175\n",
      "Epoch 77/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6161 - accuracy: 0.6748 - val_loss: 0.5846 - val_accuracy: 0.6794\n",
      "Epoch 78/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6167 - accuracy: 0.6737 - val_loss: 0.5936 - val_accuracy: 0.6757\n",
      "Epoch 79/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6168 - accuracy: 0.6736 - val_loss: 0.5761 - val_accuracy: 0.6945\n",
      "Epoch 80/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6189 - accuracy: 0.6716 - val_loss: 0.6008 - val_accuracy: 0.6838\n",
      "Epoch 81/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6173 - accuracy: 0.6734 - val_loss: 0.5867 - val_accuracy: 0.6810\n",
      "Epoch 82/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6158 - accuracy: 0.6749 - val_loss: 0.6086 - val_accuracy: 0.6893\n",
      "Epoch 83/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6148 - accuracy: 0.6761 - val_loss: 0.6127 - val_accuracy: 0.6532\n",
      "Epoch 84/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6151 - accuracy: 0.6756 - val_loss: 0.5708 - val_accuracy: 0.7088\n",
      "Epoch 85/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6149 - accuracy: 0.6755 - val_loss: 0.5993 - val_accuracy: 0.7108\n",
      "Epoch 86/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6139 - accuracy: 0.6775 - val_loss: 0.6516 - val_accuracy: 0.6524\n",
      "Epoch 87/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6141 - accuracy: 0.6765 - val_loss: 0.5910 - val_accuracy: 0.6657\n",
      "Epoch 88/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6130 - accuracy: 0.6777 - val_loss: 0.6338 - val_accuracy: 0.6750\n",
      "Epoch 89/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6140 - accuracy: 0.6766 - val_loss: 0.5841 - val_accuracy: 0.6966\n",
      "Epoch 90/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6143 - accuracy: 0.6762 - val_loss: 0.6038 - val_accuracy: 0.6467\n",
      "Epoch 91/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6170 - accuracy: 0.6736 - val_loss: 0.5709 - val_accuracy: 0.6817\n",
      "Epoch 92/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6142 - accuracy: 0.6767 - val_loss: 0.6307 - val_accuracy: 0.6560\n",
      "Epoch 93/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6127 - accuracy: 0.6781 - val_loss: 0.5712 - val_accuracy: 0.6907\n",
      "Epoch 94/100\n",
      "25186/25186 [==============================] - 95s 4ms/step - loss: 0.6133 - accuracy: 0.6770 - val_loss: 0.5916 - val_accuracy: 0.6891\n",
      "Epoch 95/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6132 - accuracy: 0.6772 - val_loss: 0.6543 - val_accuracy: 0.6076\n",
      "Epoch 96/100\n",
      "25186/25186 [==============================] - 91s 4ms/step - loss: 0.6141 - accuracy: 0.6770 - val_loss: 0.5958 - val_accuracy: 0.6736\n",
      "Epoch 97/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6144 - accuracy: 0.6769 - val_loss: 0.5984 - val_accuracy: 0.6750\n",
      "Epoch 98/100\n",
      "25186/25186 [==============================] - 93s 4ms/step - loss: 0.6158 - accuracy: 0.6749 - val_loss: 0.6035 - val_accuracy: 0.6541\n",
      "Epoch 99/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6157 - accuracy: 0.6745 - val_loss: 0.5766 - val_accuracy: 0.7060\n",
      "Epoch 100/100\n",
      "25186/25186 [==============================] - 92s 4ms/step - loss: 0.6144 - accuracy: 0.6766 - val_loss: 0.6160 - val_accuracy: 0.6415\n"
     ]
    }
   ],
   "source": [
    "mcp_spo2 = ModelCheckpoint(best_weights_filepath_spo2, monitor=\"val_accuracy\",\n",
    "                      save_best_only=True, save_weights_only=False)\n",
    "            \n",
    "history = model_spo2.fit(spo2_train, y_train_wide,\n",
    "         batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(spo2_valid, y_valid_wide),\n",
    "          callbacks=[mcp_spo2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46464,  3904],\n",
       "       [  763,   605]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_spo2.predict(spo2_test)\n",
    "predict_test=np.argmax(y_pred, axis=1)\n",
    "predict_test=predict_test.reshape(predict_test.shape[0],1)\n",
    "cm=confusion_matrix(y_test_num, predict_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097920210298438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[1,1]+cm[0,0])/(cm[1,1]+cm[1,0]+cm[0,0]+cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4422514619883041"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1,1]/(cm[1,1]+cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224904701397713"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0,0]/(cm[0,0]+cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1341760922599246"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1,1]/(cm[1,1]+cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spo21=model_spo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34220, 16148],\n",
       "       [  295,  1073]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spo21.load_weights(best_weights_filepath_spo2)\n",
    "y_pred = model_spo21.predict(spo2_test)\n",
    "predict_test=np.argmax(y_pred, axis=1)\n",
    "predict_test=predict_test.reshape(predict_test.shape[0],1)\n",
    "cm=confusion_matrix(y_test_num, predict_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6821748878923767"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cm[1,1]+cm[0,0])/(cm[1,1]+cm[1,0]+cm[0,0]+cm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7843567251461988"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1,1]/(cm[1,1]+cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6793996188055909"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0,0]/(cm[0,0]+cm[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manually pushing weights to -1 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_values=model_spo21.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=weight_values[4] #repeat for each convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check>0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check<0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1., -1.,  1., ..., -1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1., -1., ..., -1., -1., -1.],\n",
       "        [-1., -1.,  1., ...,  1.,  1., -1.],\n",
       "        [-1., -1., -1., ..., -1.,  1.,  1.]],\n",
       "\n",
       "       [[-1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "        [-1.,  1.,  1., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  1., ..., -1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1., ...,  1., -1., -1.],\n",
       "        [-1., -1.,  1., ..., -1.,  1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1., -1.]],\n",
       "\n",
       "       [[-1., -1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1., -1., -1., ...,  1., -1., -1.],\n",
       "        [ 1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "        [-1., -1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1., -1., -1., ...,  1., -1.,  1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1., -1., -1., ...,  1.,  1.,  1.],\n",
       "        [-1., -1., -1., ...,  1., -1., -1.],\n",
       "        [-1., -1.,  1., ...,  1.,  1., -1.],\n",
       "        [ 1.,  1., -1., ..., -1., -1.,  1.],\n",
       "        [-1., -1.,  1., ..., -1.,  1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1.,  1.]],\n",
       "\n",
       "       [[-1., -1.,  1., ..., -1.,  1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1., -1., -1., ...,  1., -1.,  1.],\n",
       "        [ 1.,  1., -1., ...,  1., -1.,  1.],\n",
       "        [-1., -1., -1., ...,  1., -1.,  1.],\n",
       "        [-1.,  1., -1., ...,  1., -1., -1.]],\n",
       "\n",
       "       [[-1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "        [-1., -1., -1., ...,  1.,  1., -1.],\n",
       "        [-1., -1., -1., ...,  1., -1., -1.],\n",
       "        [-1., -1., -1., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "        [-1.,  1.,  1., ..., -1.,  1., -1.]]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_values[4]=check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spo21.set_weights(weight_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45729,  4639],\n",
       "       [  378,   990]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = model_spo21.predict(spo2_test)\n",
    "predict_test=np.argmax(y_pred, axis=1)\n",
    "predict_test=predict_test.reshape(predict_test.shape[0],1)\n",
    "cm=confusion_matrix(y_test_num, predict_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spo21.save_weights(best_weights_filepath_spo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
